# 2022/2023 Josue Page Vizcaino pv.josue@gmail.com
import subprocess
import numpy as np
import torch, math, csv
import torch.nn.functional as F
import torch.nn as nn
from typing import Tuple
from tifffile import imsave
import matplotlib.pyplot as plt

from XLFMDataset import *

def get_free_gpu():
    """
    This function returns the index of the GPU with the most available memory.
    It does so by running a shell command to get the memory usage of each GPU,
    and then returns the index of the GPU with the least memory usage.
    @return The index of the GPU with the most available memory.
    """
    _, output = subprocess.getstatusoutput(
        "nvidia-smi -q -d Memory |grep -A4 GPU|grep Used"
    )
    memory_available = [int(s) for s in output.split() if s.isdigit()]
    return np.argmin(memory_available)

def get_lenslet_centers(filename):
    """
    Given a filename, read in the data and return the lenslet coordinates.
    @param filename - the name of the file containing the lenslet coordinates
    @return The lenslet coordinates as a tensor.
    """
    x,y = [], []
    with open(filename,'r') as f:
        reader = csv.reader(f,delimiter='\t')
        for row in reader:
            x.append(int(row[0]))
            y.append(int(row[1]))
    lenslet_coords = torch.cat((torch.IntTensor(x).unsqueeze(1),torch.IntTensor(y).unsqueeze(1)),1)
    return lenslet_coords

def _no_grad_trunc_normal_(tensor, mean=0, std=1, a=-1, b=1):
    """
    This function initializes the weights of a tensor using a truncated normal distribution. The function takes in a tensor, mean, standard deviation, lower bound, and upper bound. It then calculates the cumulative distribution function of the normal distribution and uses it to calculate the lower and upper bounds of the truncated normal distribution. The tensor is then initialized with values from the truncated normal distribution, transformed using the inverse error function, and scaled by the standard deviation and mean. Finally, the tensor is clamped to the specified lower and upper bounds.
    @param tensor - the tensor to initialize
    @param mean - the mean of the normal distribution
    @param std - the standard deviation of the normal distribution
    @param a - the lower bound of the truncated normal distribution
    @param b - the upper
    """
    # Method based on https://people.sc.fsu.edu/~jburkardt/presentations/truncated_normal.pdf
    def norm_cdf(x):
        # Computes standard normal cumulative distribution function
        return (1. + math.erf(x / math.sqrt(2.))) / 2.

    if (mean < a - 2 * std) or (mean > b + 2 * std):
        warnings.warn("mean is more than 2 std from [a, b] in nn.init.trunc_normal_. "
                      "The distribution of values may be incorrect.",
                      stacklevel=2)

    with torch.no_grad():
        # Values are generated by using a truncated uniform distribution and
        # then using the inverse CDF for the normal distribution.
        # Get upper and lower cdf values
        l = norm_cdf((a - mean) / std)
        u = norm_cdf((b - mean) / std)

        # Uniformly fill tensor with values from [l, u], then translate to
        # [2l-1, 2u-1].
        tensor.uniform_(2 * l - 1, 2 * u - 1)

        # Use inverse cdf transform for normal distribution to get truncated
        # standard normal
        tensor.erfinv_()

        # Transform to proper mean, std
        tensor.mul_(std * math.sqrt(2.))
        tensor.add_(mean)

        # Clamp to ensure it's in the proper range
        tensor.clamp_(min=a, max=b)
        return tensor

def fast_quantile(x, quant=0.95):
    """
    Calculate the quantile of a given input tensor or numpy array.
    @param x - the input tensor or numpy array
    @param quant - the quantile to calculate (default 0.95)
    @return The quantile value
    """
    
    if torch.is_tensor(x):
        h,ranges = torch.histogram(x, bins=10000)
    else:
        h,ranges = np.histogram(x, bins=10000)
    quant_numel = h[1:].sum() * quant
    cumulative_elements = 0
    for n_bin in range(1,len(h)):
        if cumulative_elements >= quant_numel:
            break
        cumulative_elements += h[n_bin]
    return ranges[n_bin]


def crop_volume_center(volume, volume_shape):
    """
    Crop a volume to the center of the volume.
    @param volume - the volume to crop
    @param volume_shape - the shape of the volume
    @return The cropped volume
    """
    vol_pred_crop_width = volume_shape[2]
    vol_pred_crop_height = volume_shape[3]
    vol_pred_center_x = math.floor(volume.shape[2] / 2)
    vol_pred_center_y = math.floor(volume.shape[3] / 2)
    volume = volume[
        :,
        :,
        vol_pred_center_x
        - math.floor(vol_pred_crop_width / 2) : vol_pred_center_x
        + math.ceil(vol_pred_crop_width / 2),
        vol_pred_center_y
        - math.floor(vol_pred_crop_height / 2) : vol_pred_center_y
        + math.ceil(vol_pred_crop_height / 2),
    ]
    return volume

def load_process_volume(data_path, volume_new_size=[], volume_ths=[], norm='max', resize=False, channel_order='zxy', device="cpu"):
    """
    This function loads and processes a volume from a given data path. The volume can be in either .h5 or .tif format. The volume can be resized or cropped to a given size. The volume can also be normalized by either standard deviation or maximum value. 
    @param data_path - the path to the data
    @param volume_new_size - the new size of the volume
    @param volume_ths - the threshold value for the volume
    @param norm - the normalization method to use
    @param resize - whether or not to resize the volume
    @param channel_order - the order of the channels
    @param device - the device to use
    @return the processed volume
    """
    # Check if data_path is a volume or a path
    if isinstance(data_path, str):
        if 'h5' in data_path or 'hdf5' in data_path:
            vol_file = tables.open_file(data_path, "r", driver="H5FD_CORE")
            gt_volume = (
                torch.tensor(vol_file.root.fish_phantom)
            )
            vol_file.close()
        elif 'tif' in data_path:
            gt_volume = read_tiff_stack(data_path, np.float32).to(device)#imread(data_path).squeeze().astype(np.float32)

            # gt_volume = torch.from_numpy(gt_volume).to(device)
        else:
            raise NotImplementedError
    else: # is a tensor
        gt_volume = data_path

    if gt_volume.ndim == 3:
        if channel_order=='xyz':
            gt_volume = gt_volume.permute(2, 1, 0)
        if channel_order=='yxz':
            gt_volume = gt_volume.permute(2, 0, 1)
        gt_volume = gt_volume.unsqueeze(0).to(device)
    
    if resize:
        out_volume = resize_volume(gt_volume.float(), volume_new_size)
    else:
        out_volume = crop_volume_center(gt_volume, [1,volume_new_size[2],volume_new_size[0],volume_new_size[1]])
    
    
    if norm!=None:
        if norm=='std':
            mean,std = torch.std_mean(out_volume)
            out_volume = (out_volume-mean)/std
        elif norm=='max':
            out_volume /= out_volume.max()
            out_volume[out_volume < volume_ths] = 0
    else:
        if isinstance(volume_ths,float):
            out_volume[out_volume.float()<=volume_ths*out_volume.float().max()] = 0
        elif len(volume_ths)==2:
            out_volume[out_volume.float()<volume_ths[0]] = 0
            out_volume[out_volume.float()>=volume_ths[1]] = volume_ths[1]

    return out_volume.type_as(gt_volume)


def load_XLFM_data(dataset_path, lenslet_coords_file, vol_shape, img_shape, images_to_use, n_depths_to_fill, ds_id, volume_ths, volume_quantiles, img_ths, norm):
    """
    Load and process XLFM data from a given dataset path and lenslet coordinates file.
    @param dataset_path - the path to the dataset
    @param lenslet_coords_file - the file containing the lenslet coordinates
    @param vol_shape - the shape of the volume
    @param img_shape - the shape of the images
    @param images_to_use - the images to use
    @param n_depths_to_fill - the number of depths to fill
    @param ds_id - the dataset ID
    @param volume_ths - the volume thresholds
    @param volume_quantiles - the volume quantiles [0,1.0]
    @param img_ths - the image thresholds
    @param norm - the normalization type: None, torch.max, torch.sum
    @return the processed dataset
    """
    with torch.no_grad():
        ds = XLFMDatasetFull(dataset_path, lenslet_coords_file, img_shape=img_shape,
                images_to_use=images_to_use,
                n_depths_to_fill=n_depths_to_fill,
                ds_id=ds_id)
        # Reshape volumes
        ds.vols = load_process_volume(ds.vols, vol_shape, volume_ths=volume_ths, norm=norm).float()
        ds.stacked_views = ds.stacked_views.float()

        # Quantile normalization
        if volume_quantiles[1] != 1:
            uper_ths = fast_quantile(ds.vols, volume_quantiles[1])
            ds.vols[ds.vols>uper_ths] = uper_ths
    
        img_low_ths = ds.stacked_views.max()*img_ths[0]
        ds.stacked_views[ds.stacked_views<img_low_ths] = 0
    
    return ds


def create_image_piramid(images, norm=np.max):
    """
    Create an image pyramid from a list of images. The first image is placed in the top left corner of the composite image. The remaining images are placed in a column to the right of the first image. Each subsequent image is placed below the previous image. The images are scaled to fit the composite image. The resulting composite image is returned.
    @param images - a list of images to be combined into a pyramid
    @param norm - a normalization function to be applied to the images
    @return a composite image of the image pyramid
    """
    rows, cols = images[0].shape
    rows2, cols2 = images[1].shape
    # Paint the borders black per image
    for img in images:
        border_color = img.max()
        img[0,:] = border_color
        img[-1,:] = border_color
        img[:,0] = border_color
        img[:,-1] = border_color
    torch2np = lambda i : i[0,...].permute(1,2,0).cpu().detach().numpy()
    composite_image = np.zeros((4*rows+rows2, 4*cols + cols2), dtype=np.float)
    # permute as input is b,c,x,y and we want x,y,c
    composite_image[:rows, :cols] = images[0]
    if norm is not None:
        composite_image[:rows, :cols] -= images[0].min()
        composite_image[:rows, :cols] /= norm(images[0])
    i_row = 0
    for ix,p in enumerate(images[1:]):
        n_rows, n_cols = p.shape

        if norm != None:
            p -= p.min()
            d = norm(p)
            if d==0:
                print(F'here')
                d = 1
            p = p/d
        else:
            p /= 2**(ix+1)
        
        composite_image[i_row:i_row + n_rows, cols:cols + n_cols] = (p)
        i_row += n_rows
    
    return composite_image[:i_row,:cols+cols2]


def set_all_seeds(seed):
    """
    Set the seed for all random number generators to ensure reproducibility.
    @param seed - the seed value to set
    @return None
    """
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    np.random.seed(seed)
    import random
    random.seed(seed)
    print(F'seed: {seed} set.')
    return

def volume_2_projections(vol_in, proj_type=torch.amax, scaling_factors=[1,1,2], depths_in_ch=False, ths=[0.0,1.0], normalize=False, border_thickness=2, add_scale_bars=False, scale_bar_vox_sizes=[40,20]):
    """
    This function takes a 3D volume and generates 2D projections of it along the x, y, and z axes.
    @param vol_in - the input volume
    @param proj_type - the type of projection to use (default is torch.amax)
    @param scaling_factors - the scaling factors to use for each axis (default is [1,1,2])
    @param depths_in_ch - whether the depth is in the channel dimension (default is False)
    @param ths - the thresholds to use for the volume (default is [0.0,1.0])
    @param normalize - whether to normalize the volume (default is False)
    @param border_thickness - the thickness of the border to add to the output image (default is 2)
    @param add
    """
    vol = vol_in.detach().clone().abs()
    # Normalize sets limits from 0 to 1
    if normalize:
        vol -= vol.min()
        vol /= vol.max()
    if depths_in_ch:
        vol = vol.permute(0,2,3,1).unsqueeze(1)
    if ths[0]!=0.0 or ths[1]!=1.0:
        vol_min,vol_max = vol.min(),vol.max()
        vol[(vol-vol_min)<(vol_max-vol_min)*ths[0]] = 0
        vol[(vol-vol_min)>(vol_max-vol_min)*ths[1]] = vol_min + (vol_max-vol_min)*ths[1]

    vol_size = list(vol.shape)
    vol_size[2:] = [vol.shape[i+2] * scaling_factors[i] for i in range(len(scaling_factors))]

    x_projection = proj_type(vol.float().cpu(), dim=2)
    y_projection = proj_type(vol.float().cpu(), dim=3)
    z_projection = proj_type(vol.float().cpu(), dim=4)

    out_img = z_projection.min() * torch.ones(
        vol_size[0], vol_size[1], vol_size[2] + vol_size[4] + border_thickness, vol_size[3] + vol_size[4] + border_thickness
    )

    out_img[:, :, : vol_size[2], : vol_size[3]] = z_projection
    out_img[:, :, vol_size[2] + border_thickness :, : vol_size[3]] = F.interpolate(x_projection.permute(0, 1, 3, 2), size=[vol_size[-1],vol_size[-3]], mode='nearest')
    out_img[:, :, : vol_size[2], vol_size[3] + border_thickness :] = F.interpolate(y_projection, size=[vol_size[2],vol_size[4]], mode='nearest')


    if add_scale_bars:
        line_color = 1.0
        # Draw white lines
        out_img[:, :, vol_size[2]: vol_size[2]+ border_thickness, ...] = line_color
        out_img[:, :, :, vol_size[3]:vol_size[3]+border_thickness, ...] = line_color

    return out_img


def imshow2D(img, blocking=False):
    """
    Display a 2D image using matplotlib.
    @param img - the image to display
    @param blocking - whether or not to block the program until the window is closed
    @return None
    """
    plt.figure(figsize=(10,10))
    plt.imshow(img[0,0,...].float().detach().cpu().numpy())
    if blocking:
        plt.show()

def imshow3D(vol, blocking=False, normalize=True, color_map='gray',add_scale_bars=False):
    """
    Display a 3D volume as a 2D projection image.
    @param vol - the 3D volume to display
    @param blocking - whether to block the program until the window is closed
    @param normalize - whether to normalize the volume
    @param color_map - the color map to use for the image
    @param add_scale_bars - whether to add scale bars to the image
    @return None
    """
    plt.figure(figsize=(10,10))
    plt.imshow(volume_2_projections(vol.permute(0,2,3,1).unsqueeze(1), normalize=normalize, add_scale_bars=add_scale_bars)[0,0,...].float().detach().cpu().numpy(), cmap=color_map)
    plt.axis('off')
    plt.tight_layout()
    if blocking:
        plt.show()

def save_image(tensor, path='output.png',color_map='gray'):
    """
    Save an image to a specified path. If the tensor is 3D, display it using imshow3D. If it is 2D, display it using imshow2D. If the path is a tif file, save the tensor as a tif file using imsave.
    @param tensor - the tensor to save
    @param path - the path to save the image to
    @param color_map - the color map to use when displaying the image
    @return None
    """
    if tensor.ndim<4:
        tensor = tensor.unsqueeze(0)
    if 'tif' in path:
        imsave(path, tensor[0,...].cpu().numpy().astype(np.float16))
        return
    if tensor.shape[1] == 1:
        imshow2D(tensor)
    else:
        imshow3D(tensor, color_map=color_map)
    plt.savefig(path, bbox_inches='tight',pad_inches = 0)


def psnr(img1, img2, PIXEL_MAX = 1.0):
    """
    Calculate the peak signal-to-noise ratio (PSNR) between two images.
    @param img1 - the first image
    @param img2 - the second image
    @param PIXEL_MAX - the maximum pixel value (default is 1.0)
    @return The PSNR value
    """
    mse = torch.mean( (img1 - img2) ** 2 )
    if mse == 0:
        if img1.sum()==0:
            return torch.tensor([0])
        return torch.tensor([100])
    
    return 20 * torch.log10(PIXEL_MAX / torch.sqrt(mse))

def composite_projection(tensor):
    """
    This function takes a 3D tensor and returns a composite projection of the tensor
    onto the xy, xz, and yz planes.
    @param tensor - a 3D tensor
    @return composite - a composite projection of the tensor onto the xy, xz, and yz planes.
    """
    # Compute the xy projection
    xy_projection = np.max(tensor, axis=0)
    # Compute the xz projection
    xz_projection = np.max(tensor, axis=1)
    # Compute the yz projection
    yz_projection = np.max(tensor, axis=2)
    # Transpose the yz projection to make its shape compatible with the top_half array
    yz_projection = np.transpose(yz_projection, (1, 0, 2))
    # Add padding to the yz projection
    yz_projection = np.pad(yz_projection, ((xz_projection.shape[0], 0), (0, 0), (0, 0)), mode='constant')
    # Stack the xy and xz projections vertically to create the first part of the composite image
    top_half = np.vstack((xy_projection, xz_projection))
    # Stack the yz projection and the first part horizontally to create the composite image
    composite = np.hstack((top_half, yz_projection))
    return composite

def filter_data(data, kernel_size=10):
    """
    Given a data array and a kernel size, filter the data using a moving average filter.
    @param data - the data array to be filtered
    @param kernel_size - the size of the kernel to be used in the moving average filter
    @return The filtered data array
    """
    kernel = np.ones(kernel_size) / kernel_size
    return np.convolve(data, kernel, mode='same')
    
def norm_data(data, filter=10):
    """
    Normalize the input data by subtracting the minimum value and dividing by the maximum value.
    @param data - the input data
    @param filter - the filter to apply to the data
    @return The normalized data and the range of the data
    """
    d1 = data * 1.0 # copy data
    if filter!=0:
        d1 = filter_data(d1, filter)
    min_d1 = min(d1)
    max_d1 = max(d1)
    d1 = d1-min_d1
    m_d1 = max_d1
    if m_d1 == 0:
        m_d1 = 1
    d2 = d1 / m_d1
    return d2,max_d1-min_d1,
